---
title: "Predicting classe"
output:
   html_document:
       toc: true
       theme: readable
       highlight: zenburn
       keep_md: true
---

## Predicting classe variable
```{r setup, echo = FALSE}
library(knitr)
opts_chunk$set(cache = TRUE, message=FALSE)
```

The goal of of this analysis was to predict the 'classe' variable using data from https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv.  The actual meaning of the variables was ignored for this analysis.

## Step 1: choosing predictor variables
```{r pars, echo = F}
tsize <- 1000
cvsize <- 3000
```

First, timestamps and username columns were removed.  Then, columns with factor variables were ignored simply to reduce the amount of work needed to create dummy variables and to reduce to overall number of possible variables.  Then, columns with all NA values in the test data set were excluded from the training data set.  Finally, a random subset (`r tsize` rows) of the trimmed data was selected as a training set for the model.

```{r variables, results = "hide"}
train <- read.csv("pml-training.csv")
test <- read.csv("pml-testing.csv")

## Ignore factor columns
ccs <- which(sapply(names(train), function(i)
                    class(train[,i])) != "factor")
classe <- train$classe
train <- train[,ccs]
test <- test[,ccs]

## Remove some NA columns and timestamps
sapply(1:ncol(train), function(i) nrow(train[is.na(train[,i]),]))
sapply(1:ncol(test), function(i) nrow(test[is.na(test[,i]),]))
nacols <- which(sapply(1:ncol(test), function(i) all(is.na(test[,i]))))
test <- test[,-c(1:4,nacols)]
train <- train[,-c(1:4,nacols)]

## Use subset of train for fitting
set.seed(1000)
samp <- sample(1:nrow(train), tsize)
trn <- train[samp,]
cs <- classe[samp]

```
The resulting training set used `r ncol(trn)` variables as predictors.

## The model
The train() function for the caret package was used as a wrapper to fit a random forest model from the R package 'randomForest'.  The random forest model was fit using default settings.

```{r model}
require(caret)
mod <- train(cs ~ ., method = "rf", data = trn, verbose=FALSE)
pred <- predict(mod, test)
```

## Cross-validation
A subset of the training data set (`r cvsize` rows) that was not used for the actual training of the model was selected for cross-validation.

```{r cv}
cvsamp <- sample(1:nrow(train)[-samp], cvsize)
cv <- train[cvsamp, ]
cvpred <- predict(mod, cv)
confMat <- confusionMatrix(classe[cvsamp], cvpred)
acc <- confMat$overall[["Accuracy"]]
lwr <- confMat$overall[["AccuracyLower"]]
upr <- confMat$overall[["AccuracyUpper"]]

```

## Conclusion
So, using a training set of size `r tsize` and a cross-validation set of size `r cvsize` a random forest model achieved an accuracy of `r acc` (95% CI: (`r lwr`, `r upr`)).
